{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae6289d-998e-42ed-8ade-d9a55526d67b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Workbook 4: Local Search in categorical and continuous spaces\n",
    "## Introduction\n",
    "This workbook focusses on the final search algorithm that we have discussed but not asked you to implement so far: Local Search.  \n",
    "\n",
    "We will focus on perturbative approaches\n",
    "\n",
    "To develop your understanding you will:\n",
    "- Start with a simple binary problem that local search should be able to solve.\n",
    "- Look at a binary problem local search cannot solve without some changes\n",
    "- Adapt the **SingleMemberSearch** class to work with continuous decision variables,  \n",
    "   using  continuous version of the first binary problem. \n",
    "\n",
    "## Aims of this practical\n",
    "1. To give you the experience of  implementing, and evaluating the behaviour of local search in categorical problems.\n",
    "2. To give you experience of comparing the behaviour of different search algorithms.\n",
    "3. To give you experience of evaluating the efficiency of an algorithm for a problem ( in this case path-planning) by creating different instances of a problem (mazes) to *stress-test* different methods. \n",
    "\n",
    "# This is not an assessed workbook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd62e37-11a7-4d2c-b1be-2928935831e5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "## reminder: Pseudocode for function SelectAndMoveFromOpenList in Local Search\n",
    "### This assumes the search process maintains track of *bestSoFar*\n",
    "<div style=\"background:#F0FFFF;font-size:18pt\">\n",
    "<p style=\"color:darkred;font-size:18pt;margin-bottom:0pt\"><em>SelectAndMoveFromOpenList</em></p>\n",
    "<dl style=\"font-size:18pt;margin-top:0pt\">\n",
    "    <dt>&nbsp;&nbsp;&nbsp;<b>IF</b> IsEmpty( open_list) <b>THEN</b> </dt>\n",
    "    <dd> RETURN None</dd>\n",
    "    <dt> &nbsp;&nbsp;&nbsp;<b>ELSE</b></dt>\n",
    "    <dd>bestChild &larr; <b>GetMemberWithHighestQuality</b>(openList)</dd>\n",
    "    <dd> <b>EMPTY</b>(openlist)&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"background:pink\">This prevents backtracking</span></dd>\n",
    "    <dd>  <b>IF</b> BetterThan(bestChild, bestSoFar) <b>THEN</b> <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;bestSoFar &larr; bestChild <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;RETURN bestChild </dd>\n",
    "    <dd> <b>ELSE</b> <br>&nbsp;&nbsp;&nbsp;&nbsp; RETURN None</dd>\n",
    "</dl>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19af297-72bb-491a-996c-a0042b2d6f9b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 1: implementing local search for a binary problem</h2>\n",
    "    <ul>\n",
    "        <li>Run the first cell to do some standard imports.</li>\n",
    "    <li>Then complete the second cell which contains an incomplete implementation of local search.</li>\n",
    "    <li> Test your implementation by running the third cell which uses your implementation to solve the <em>OneMax</em> problem. <br>\n",
    "        This is a simple binary maximisation problem where the quality is the number of the decision variables set to 1.</li>\n",
    "        </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836ccbd6-c5e7-45de-a75f-483aae36409a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.628294Z",
     "start_time": "2024-04-02T01:20:56.611339Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from candidatesolution import CandidateSolution\n",
    "from singlemembersearch import SingleMemberSearch\n",
    "from problem import Problem\n",
    "from onemaxproblem import OneMaxBinary, OneMaxContinuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b3cea1-eb18-43ff-b1ac-5f5b8c46b2f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.643895Z",
     "start_time": "2024-04-02T01:20:56.629295Z"
    }
   },
   "outputs": [],
   "source": [
    "class LocalSearch(SingleMemberSearch):\n",
    "    \"\"\"Implementation of local search.\"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"local search\"\n",
    "\n",
    "    def get_member_with_highest_quality(self):\n",
    "        index = 0\n",
    "        for item in range(len(self.open_list)):\n",
    "            index = item if self.open_list[item].quality > self.open_list[index].quality else index\n",
    "        return index\n",
    "            \n",
    "\n",
    "    def select_and_move_from_openlist(self) -> CandidateSolution:\n",
    "        \"\"\"Pops best thing from list, clears rest of list, then returns best thing\n",
    "        relies on the presence of self.best_so_far\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next\n",
    "           working candidate (solution) taken from open list\n",
    "           if it is an improvement\n",
    "        None\n",
    "           IF list is empty OR next thing is worse than best so far\n",
    "        \"\"\"\n",
    "        next_soln = CandidateSolution()\n",
    "        best = self.open_list.pop(self.get_member_with_highest_quality())\n",
    "        better = self.a_better_than_b(best.quality, self.best_so_far)\n",
    "        self.best_so_far = best.quality if better else self.best_so_far\n",
    "        return best if better else None\n",
    "        # self.open_list = sorted(self.open_list, key=lambda item: item.quality, reverse=True)\n",
    "        # return self.open_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544a8024-6964-4821-a605-494e24d122de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.659214Z",
     "start_time": "2024-04-02T01:20:56.644538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality of starting choices [1, 1, 1, 0, 0, 0, 1, 0, 1, 1] is 6.0\n",
      "Local Search solved the problem  after 34 attempts.\n"
     ]
    }
   ],
   "source": [
    "num_vars = 10\n",
    "binary_onemax = OneMaxBinary(N=num_vars)\n",
    "mysearch = LocalSearch( binary_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=False,\n",
    "                        target_quality=num_vars)\n",
    "# default behaviour is to initialise with all zeroes\n",
    "# change to random initialisation\n",
    "for i in range(num_vars):\n",
    "    mysearch.open_list[0].variable_values[i] = np.random.choice(binary_onemax.value_set)\n",
    "#get new score\n",
    "quality,_ = binary_onemax.evaluate(mysearch.open_list[0].variable_values)\n",
    "mysearch.open_list[0].quality = quality\n",
    "print(f'quality of starting choices {mysearch.open_list[0].variable_values} is {quality}')\n",
    "    \n",
    "\n",
    "success = mysearch. run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch.trials} attempts.'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch.runlog}'\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff9ec1-c088-4958-a1a9-a6bd7c1ffb6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 2: Evaluating your implementation of implementing local search</h2>\n",
    "    Once your code works and the cell above runs and finds a solution, it is time to evaluate its performance. <ul>\n",
    "    <li>Run the cell above ten times with <em>num_vars= 10</em> and note the number of attempts needed to solve the problem.</li>\n",
    "    <li> You might like to record these in an excel spreadsheet or similar</li>\n",
    "    <li> You might also chose to edit the code to automatically run 10 times and calculate the mean and standard deviation of the number of trials</li>\n",
    "    <li> <b> HINT:</b> Don't forget that if you put the results in a numpy array, numpy will calculate these for you if you ask nicely!</li>\n",
    "    <li>Then repeat, increasing the value of <em>num_vars</em> from 10 to 30 in steps of five </li>\n",
    "    <li> Plot your results as a curve of mean values (y-axis) vs num_varrs (x-axis) with error bars showing the standard deviation.</li>\n",
    "        </ul>\n",
    "    Can you explain what it is that makes this problem so easy?\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b69ef3-8c20-42a5-8e48-a2fc4e090f74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.674964Z",
     "start_time": "2024-04-02T01:20:56.660262Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75e1ed83-167e-45ed-a935-83243d0aca06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 3: Adapting local search for a continuous problem</h2>\n",
    "    <h3> This is a stretch activity for the more confident coders.</h3>\n",
    "    <p>For continuous problems you will need to adapt your local search class.</p>\n",
    "    <p>This requires adapting more of the methods from the single member search class</p>\n",
    "    <p>I've suggested code that changes the <em>__init__</em> method \n",
    "            to initialise with appropriate continuous values,\n",
    "        and stores the number of samples to take from the neighbourhood each iteration, and whether to use gradient-based search or not.</p>\n",
    "    <p> So the first thing you need to do is over-ride the <em>select_and_move_from_openlist(self)</em> method\n",
    "        from your LocalSearch class so that it now accepts solutions that are as good \n",
    "        as <em>self.best_so_far</em> and not just improvements.</p>\n",
    "    <p> Then you need to over-ride and change the <em>run_search()</em> method so that it:</p>\n",
    "        <ol> \n",
    "            <li>generates a number of neighbours defined by self.sample_size</li>\n",
    "            <li> for each neighbour creates a set of changes (one for each decision) then adds those then truncates to the valid range of values (using function provided()\n",
    "            <li> If  <em> self.use_gradients</em> is <em>False</em> it generates the list of changes at random <br>\n",
    "                If it is <em>True</em> it calls <em>self.problem.get_gradient()</em> then multiplies the result by <em>self.learning_rate</em> to get the changes</li>\n",
    "            <li> after looking at all of the neighbours, if they were all worse than what we had already, the open_list will be empty, so you  you need to put the <em>working_candidate</em> back on the open list instead of the closed list.</li> \n",
    "        </ol>\n",
    "\n",
    " <h3> This version of the problem has a quality function that is the difference to  the target so it needs to be minimised</h3>   \n",
    "    <p>It also provides a <em>get_gradient() method</em> so you can try both approaches described in the lecture</p>   \n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "280e72ed-36f5-4bde-a15a-f3c053b44c14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T01:37:36.826144Z",
     "start_time": "2024-04-02T01:37:36.808378Z"
    }
   },
   "outputs": [],
   "source": [
    "  class LocalSearchContinuous(SingleMemberSearch):\n",
    "    \"\"\"Implementation of local search for continuous problems.\n",
    "      Assumes the search mode is perturbative.\n",
    "      Extends single member search by doing explicit sampling of neighbourhood\n",
    "      and if not stopping if no improvment is  found in an iteration\n",
    "      Parameters\n",
    "      ---------\n",
    "      sample_size(int): \n",
    "          number of neighbours to generate each iteration\n",
    "          default 10\n",
    "      use_gradient(bool): \n",
    "          whether to use the gradient instead of random changes\n",
    "          if the problem supports it.\n",
    "          If set, assume sample_size is 1\n",
    "          default False\n",
    "      learning_rate(float)\n",
    "          multiplier for gradient if used\n",
    "          default 0.5\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"local search continuous\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        problem: Problem,\n",
    "        constructive: bool = False,\n",
    "        max_attempts: int = 50,\n",
    "        minimise:bool=True,\n",
    "        target_quality:float=1,\n",
    "        sample_size:int = 10,\n",
    "        use_gradient:bool=False,\n",
    "        learning_rate=0.5\n",
    "    ):   \n",
    "        super().__init__(problem, constructive=constructive,\n",
    "                       max_attempts=max_attempts,\n",
    "                       minimise=minimise,\n",
    "                       target_quality=target_quality)\n",
    "        print(f'self.target_quality is {self.target_quality}') \n",
    "        #reinitialise to random continuous values in right range\n",
    "        self.num_vars  = len(self.open_list[0].variable_values)        \n",
    "        for decision in range(self.num_vars):\n",
    "            self.open_list[0].variable_values[decision]= self.rand_in_range()\n",
    "        #re-evaluate\n",
    "        quality,_ = self.problem.evaluate(self.open_list[0].variable_values)\n",
    "        self.open_list[0].quality=quality    \n",
    "\n",
    "        #store the number of neighbours to examine each iteration \n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        #does the problem support calculation of gradients\n",
    "        self.use_gradient= use_gradient\n",
    "        self.learning_rate = learning_rate\n",
    "        if self.use_gradient:\n",
    "            try:\n",
    "                _=self.problem.get_gradient()\n",
    "                self.sample_size = 1\n",
    "            except:\n",
    "                self.use_gradient=False\n",
    "\n",
    "    def rand_in_range(self)->float:\n",
    "        \"\"\" generates a random number in the range\n",
    "        specified by the problem\n",
    "        \"\"\"\n",
    "        lowest_val = self.problem.value_set[0]\n",
    "        val_range = self.problem.value_set[1] - self.problem.value_set[0]\n",
    "        return np.random.random()*val_range +lowest_val\n",
    "    \n",
    "    def get_rand_normals_in_range(self)->list:\n",
    "        \"\"\" \n",
    "        generates random number form  normal distribtion\n",
    "        mean= midpoint of valid range for problem\n",
    "        sdev = 10% of valid range. for problem\n",
    "        \"\"\"\n",
    "        changes=[]\n",
    "        valrange = self.problem.value_set[1]-self.problem.value_set[0]\n",
    "        valmean =  (self.problem.value_set[1]+ self.problem.value_set[0])/2\n",
    "        for pos in range(self.num_vars):\n",
    "            randval= np.random.normal() *0.1*valrange + valmean\n",
    "            changes.append(randval)\n",
    "        return changes\n",
    "        \n",
    "    \n",
    "    \n",
    "    def truncate_to_range(self, val:float)->float:\n",
    "        \"\"\" truncates a val ot the valid range\n",
    "        defined by a problem\"\"\"\n",
    "        if val>self.problem.value_set[1]:\n",
    "            val = self.problem.value_set[1]\n",
    "        if val < self.problem.value_set[0]:\n",
    "            val = self.problem.value_set[0]\n",
    "        return val\n",
    "    \n",
    "    def a_better_than_b(self, a: int, b: int) -> bool:\n",
    "        \"\"\" Compares two solutions taking into account whether we are minimising.\"\"\"\n",
    "        better: bool = False\n",
    "        if a <= b and self.minimise:\n",
    "            better = True\n",
    "        if a >= b and not self.minimise:\n",
    "            better = True\n",
    "        return better\n",
    "    \n",
    "    def select_and_move_from_openlist(self) -> CandidateSolution:\n",
    "        best = self.open_list.pop(self.get_member_with_highest_quality())\n",
    "        better = self.a_better_than_b(best.quality, self.best_so_far)\n",
    "        self.best_so_far = best.quality if better else self.best_so_far\n",
    "        return best if better else None\n",
    "    \n",
    "    def run_search(self) -> bool:\n",
    "        \"\"\"Then you need to over-ride and change the run_search() method so that it:\n",
    "        generates a number of neighbours defined by self.sample_size\n",
    "        for each neighbour creates a set of changes (one for each decision) then adds those then truncates to the valid range of values (using function provided()\n",
    "        If self.use_gradients is False it generates the list of changes at random If it is True it calls self.problem.get_gradient() then multiplies the result by self.learning_rate to get the changes\n",
    "        after looking at all of the neighbours, if they were all worse than what we had already, the open_list will be empty, so you you need to put the working_candidate back on the open list instead of the closed list.\n",
    "\"\"\"\n",
    "        \"\"\"The main loop for single member search.\n",
    "        Returns True/False for success or failure.\n",
    "        \"\"\"\n",
    "        self.trials = 1  # used 1 in init\n",
    "\n",
    "        # === Pseudocode:  WHILE IsNotEmpty( open_list) DO\n",
    "        # add a couple of other conditions to provide early stopping\n",
    "        while self.trials < self.max_attempts and not self.solved:\n",
    "            self.runlog += f\"{len(self.open_list)} candidates on the openList.\\n\"\n",
    "\n",
    "            # === Pseudocode: working_candidate <- SelectAndMoveFromOpenList(algorithm_name)\n",
    "            working_candidate = self.select_and_move_from_openlist()\n",
    "            if working_candidate is None:\n",
    "                self.runlog += \"ran out of promising solutions to test\\n\"\n",
    "                return False\n",
    "\n",
    "            # === Pseudocode: FOR sample in SAMPLE_SIZE DO\n",
    "            self.runlog += (\n",
    "                \" Next iteration working candidate quality \"\n",
    "                f\"{working_candidate.quality}.\\n\"\n",
    "            )\n",
    "            for pos in self.positions:\n",
    "                for newval in self.problem.value_set:\n",
    "                    # ==== GENERATE === #\n",
    "                    # make deepcopy so the original is not changed\n",
    "                    neighbour = deepcopy(working_candidate)\n",
    "\n",
    "                    # PS neighbour ← ApplyMoveOperator (working_candidate)\n",
    "                    if self.constructive:  # extend current solution\n",
    "                        neighbour.variable_values.append(newval)\n",
    "\n",
    "                    else:  # perturbative changes existing values\n",
    "                        neighbour.variable_values[pos] = newval\n",
    "                        oldval = working_candidate.variable_values[pos]\n",
    "                        # avoid retesting to be efficient\n",
    "                        if self.already_seen(neighbour) or newval == oldval:\n",
    "                            continue\n",
    "\n",
    "                    # === TEST === #\n",
    "                    # === Pseudocode: status ← Test ( neighbour)       Problem-specific code\n",
    "                    neighbour.quality, neighbour.reason = self.problem.evaluate(\n",
    "                        neighbour.variable_values\n",
    "                    )\n",
    "                    self.trials += 1\n",
    "\n",
    "                    # === UPDATE WORKING MEMORY === #\n",
    "                    self.update_working_memory(neighbour)\n",
    "                    if self.solved:\n",
    "                        return True\n",
    "\n",
    "            # end over loop of neighbors of working candidate\n",
    "            # === Pseudocode: AppendToClosedList(workingCandidate)\n",
    "            self.closed_list.append(working_candidate)\n",
    "\n",
    "        # while loop has ended\n",
    "        if not self.solved:\n",
    "            self.runlog += \"failed to find solution to the problem in the time allowed!\"\n",
    "        return self.solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eab913-601a-4048-820a-2acc354a01b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.706158Z",
     "start_time": "2024-04-02T01:20:56.691717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.target_quality is 0.0\n",
      "failed to solve the problem in 500 trials\n",
      " runlog is:\n",
      " 1 candidates on the openList.\n",
      "\t best child quality 1.21,\n",
      "\t best so far 10.0\n",
      "ran out of promising solutions to test\n"
     ]
    }
   ],
   "source": [
    "#search using option 1 from the lectures- adding gaussian n oise\n",
    "num_vars = 10\n",
    "continuous_onemax = OneMaxContinuous(N=num_vars)\n",
    "mysearch2 = LocalSearchContinuous( continuous_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=True,\n",
    "                        target_quality=0.0)\n",
    "    \n",
    "\n",
    "success = mysearch2.run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch2.trials} attempts.\\n'\n",
    "           f'solution {mysearch2.result}\\n'\n",
    "           f' quality {mysearch2.problem.evaluate(mysearch2.result)[0]}'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch2.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch2.runlog}'\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72077101-54e9-4089-97b5-4d1e4dc67e93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.721882Z",
     "start_time": "2024-04-02T01:20:56.707194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.target_quality is 0.0\n",
      "failed to solve the problem in 500 trials\n",
      " runlog is:\n",
      " 1 candidates on the openList.\n",
      "\t best child quality 3.43,\n",
      "\t best so far 10.0\n",
      "ran out of promising solutions to test\n"
     ]
    }
   ],
   "source": [
    " #Now search using the gradient information\n",
    "\n",
    "mysearch3 = LocalSearchContinuous( continuous_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=True,\n",
    "                        target_quality=0.0,\n",
    "                        use_gradient=True,\n",
    "                        learning_rate=0.5)    \n",
    "\n",
    "success = mysearch3.run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch3.trials} attempts.\\n'\n",
    "           f'solution {mysearch3.result}\\n'\n",
    "           f' quality {mysearch3.problem.evaluate(mysearch2.result)[0]}'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch3.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch3.runlog}'\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa229165-f33a-4be0-8c96-393e244ad855",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.737501Z",
     "start_time": "2024-04-02T01:20:56.722933Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d40939-9924-46ee-b73c-8bbdd937e1f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.753077Z",
     "start_time": "2024-04-02T01:20:56.738515Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3529b415-8528-4c76-abf9-b833471d33e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-04-02T01:20:56.768784Z",
     "start_time": "2024-04-02T01:20:56.755168Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
